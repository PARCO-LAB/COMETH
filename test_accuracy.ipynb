{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils.evaluation import *\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# data_path=\"/home/emartini/nas/MAEVE/dataset/panoptic-toolbox/trtpose3D/\"\n",
    "data_path=\"tmp/ultimatum/\"\n",
    "\n",
    "result_path=\"/home/emartini/nas/MAEVE/dataset/panoptic-toolbox/results/\"\n",
    "date = datetime.fromtimestamp(time.time()).strftime('%Y_%m_%d_%H_%m')\n",
    "CONTINUOUS_STATE_PARTS = [\n",
    "            \"nose\", \"left_ear\", \"right_ear\", \"left_shoulder\", \"right_shoulder\", \n",
    "            \"left_elbow\", \"right_elbow\", \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\", \"left_knee\", \n",
    "            \"right_knee\", \"left_ankle\", \"right_ankle\", \"neck\"]\n",
    "\n",
    "# Load the json for comparison\n",
    "mapping = [12, 7, 10, 4,  5, 9, 6, 8, 11, 3, 14, 13]\n",
    "header = [\"frame_id\"]+[CONTINUOUS_STATE_PARTS[m] for m in mapping]\n",
    "\n",
    "people = {  \"170915_office1\": 1,\n",
    "            \"161029_tools1\": 2,\n",
    "            \"161029_build1\": 2,\n",
    "            \"160422_ultimatum1\": 7,\n",
    "            \"170407_haggling_a1\": 3,\n",
    "            \"161029_sports1\": 2, # Not working\n",
    "            \"160906_band4\": 3 # Not working\n",
    "        }\n",
    "\n",
    "# HOTA parameters\n",
    "# step_min = 0.20\n",
    "# step_max = 0.50\n",
    "# step_size = 0.05\n",
    "step_min = 0.05\n",
    "step_max = 0.95\n",
    "step_size = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compared methods\n",
    "from multiprocessing import Process, Manager\n",
    "manager = Manager()\n",
    "\n",
    "# cameras_list = [[6,7],[6,7,8],[6,7,8,9],[6,7,8,9,10]]\n",
    "# cameras_list = [[6,7],[6,8],[6,9],[6,10],[7,8],[7,9],[7,10],[8,9],[8,10],[9,10]]\n",
    "\n",
    "# All the combinantions\n",
    "cameras_list = [[6], [7], [8], [9], [10]] +\\\n",
    "                generate_combinations([6,7,8,9,10],2)+\\\n",
    "                generate_combinations([6,7,8,9,10],3)+\\\n",
    "                generate_combinations([6,7,8,9,10],4)+\\\n",
    "                generate_combinations([6,7,8,9,10],5)\n",
    "\n",
    "# cameras_list = [[6], [7], [8], [9], [10]] + generate_combinations([6,7,8,9,10],2)\n",
    "# cameras_list = generate_combinations([6,7,8,9,10],5)\n",
    "# cameras_list = [[6]]\n",
    "methods = [\"openptrack\"] # \"openptrack\",\"befine\",\"cometh\" \n",
    "sequences = [\"160422_ultimatum1\"] #\"170915_office1\",\"161029_tools1\",\"161029_build1\",\"160422_ultimatum1\",\"170407_haggling_a1\",] # \"161029_sports1\"\n",
    "version = \"3\"\n",
    "\n",
    "result = []\n",
    "for sequence_name in sequences:\n",
    "    print(sequence_name)\n",
    "    for cameras in cameras_list:\n",
    "        print(\"cams:\",cameras)\n",
    "        \n",
    "        # Skip the tools cameras 8,9,10:\n",
    "        if  sequence_name == \"161029_tools1\" and any(e in [7,8,9,10] for e in cameras):\n",
    "            continue\n",
    "        \n",
    "        for method in methods:\n",
    "            print(method)\n",
    "            preprocess_time = time.time()\n",
    "            # Load ground truth\n",
    "            GT = {}\n",
    "            with open(os.path.join(data_path,sequence_name+\".gt.json\"), \"r\") as f:\n",
    "                ground_truth = json.load(f)\n",
    "            for frame in ground_truth:\n",
    "                GT[frame[\"timestamp\"]] = frame        \n",
    "\n",
    "            # Load dut file\n",
    "            DUT = {}\n",
    "            with open(os.path.join(data_path,sequence_name+\".\"+ method+\".\" +\".\".join(map(str, cameras)) +\".json\" ), \"r\") as f:\n",
    "                file = json.load(f)\n",
    "            for frame in file:\n",
    "                DUT[frame[\"timestamp\"]] = frame    \n",
    "\n",
    "            ## Build the triple nested list (shape: n_frames, n_people, n_joints, 3) and IDs (shape: n_frames, n_people)\n",
    "            # union of both gt and dut            \n",
    "            ids = list(GT.keys())\n",
    "            for frame_dut in list(DUT.keys()):\n",
    "                if frame_dut not in ids:\n",
    "                    ids.append(frame_dut) \n",
    "                    \n",
    "            predicted_keypoints = []\n",
    "            predicted_ids = []\n",
    "            ground_truth_keypoints = []\n",
    "            ground_truth_ids = []\n",
    "            for id in sorted(ids):\n",
    "                predicted_keypoints_per_frame = []\n",
    "                predicted_ids_per_frame = []\n",
    "                ground_truth_keypoints_per_frame = []\n",
    "                ground_truth_ids_per_frame = []\n",
    "                if id in GT.keys():\n",
    "                    for pp in GT[id]['continuousState']:\n",
    "                        s = np.array([ [np.nan,np.nan,np.nan] if not f else f for f in pp])\n",
    "                        s = s[mapping,:]\n",
    "                        ground_truth_keypoints_per_frame.append(s)\n",
    "                    for i in GT[id]['track_ids']:\n",
    "                        ground_truth_ids_per_frame.append(i)\n",
    "                if id in DUT.keys():\n",
    "                    for i,pp in enumerate(DUT[id]['continuousState']):\n",
    "                        s = np.array([ [np.nan,np.nan,np.nan] if not f else f for f in pp])\n",
    "                        s = s[mapping,:]\n",
    "                        if not np.isnan(s).all():\n",
    "                            predicted_keypoints_per_frame.append(s)\n",
    "                    # This doesn't work for cameras\n",
    "                    for I in DUT[id]['track_ids']:\n",
    "                        predicted_ids_per_frame.append(I)\n",
    "                \n",
    "                predicted_keypoints.append(predicted_keypoints_per_frame)\n",
    "                predicted_ids.append(predicted_ids_per_frame)\n",
    "                ground_truth_keypoints.append(ground_truth_keypoints_per_frame)\n",
    "                ground_truth_ids.append(ground_truth_ids_per_frame)\n",
    "\n",
    "            preprocess_time = time.time() - preprocess_time\n",
    "            print(\"pre-process time:\",round(preprocess_time,2),\"s\")\n",
    "            # Compute HOTA\n",
    "            process_time = time.time()\n",
    "            res = manager.list()\n",
    "            procs = []\n",
    "            step = step_min\n",
    "            thread_id = 0\n",
    "            while step <= step_max:\n",
    "                proc = Process(target=hota_par, args=(res,thread_id,predicted_keypoints, predicted_ids, ground_truth_keypoints, ground_truth_ids,step))\n",
    "                procs.append(proc)\n",
    "                proc.start()\n",
    "                step += step_size\n",
    "                thread_id += 1\n",
    "\n",
    "            for proc in procs:\n",
    "                proc.join()\n",
    "            \n",
    "            process_time = time.time() - process_time\n",
    "            print(\"process time:\",round(process_time,2),\"s\")\n",
    "            \n",
    "            res = list(res)\n",
    "            # row = [sequence_name,len(cameras),method] + list(np.nanmean(np.array(res),0)[1:])\n",
    "            row = [sequence_name,people[sequence_name],len(cameras),\",\".join(map(str, cameras)),method] + np.round(list(100*np.nanmean(np.array(res),0)),1).tolist()\n",
    "            result.append(row)\n",
    "            \n",
    "        header_stats = [\"Sequence\", \"#People\",\"#Cams\",\"Cams\", \"Aggregator\",  \"LocA\", \"DetA\", \"DetPR\", \"DetRE\", \"AssA\",\"AssPR\",\"AssRE\", \"HOTA\"]\n",
    "        df = pd.DataFrame(result,columns=header_stats)\n",
    "        print(df[[\"Cams\", \"Aggregator\", \"LocA\", \"DetA\", \"AssA\",\"HOTA\"]].tail(len(methods)).to_string())\n",
    "df.to_csv(os.path.join(result_path,date+\"_\"+sequence_name+'_V'+version+'.csv'), index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[[\"Cams\", \"Aggregator\", \"LocA\", \"DetA\", \"AssA\",\"HOTA\"]].to_string())\n",
    "print(df.groupby([\"#Cams\",\"Aggregator\"]).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

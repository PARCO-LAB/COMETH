{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5128bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import nimblephysics as nimble\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from COMETH import Skeleton, DynamicSkeleton\n",
    "from sf_utils import input_sim, rotation, sk_model, dh_model, kalman\n",
    "from sf_utils.metrics import body_pose_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------File names-------------#\n",
    "imu_data_path = os.path.abspath('raw_imu_data/imu_s1_acting1.csv')\n",
    "vicon_data_path = os.path.abspath('./totalcapture/vicon')\n",
    "subj = 's1'\n",
    "action = 'acting1'\n",
    "saving_dir = f'./{subj}_{action}'\n",
    "\n",
    "#----------Other constants--------#\n",
    "# Framerate\n",
    "dt = 1/60\n",
    "\n",
    "# Camera rotation matrix respect to thorx IMU\n",
    "theta_cam = np.deg2rad(-75)\n",
    "R_cam_imu = np.array([[np.cos(theta_cam), 0, np.sin(theta_cam)],[0,1,0],[-np.sin(theta_cam),0,np.cos(theta_cam)]])\n",
    "\n",
    "# Ratio between camera and imu framerates\n",
    "ratio = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1acc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ground-truth\n",
    "target, pos_gt, offset = sk_model.compute_gt(os.path.join(subj, action), vicon_data_path, comp_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting accelerometer and gyroscope data from file\n",
    "imu_cont = input_sim.ImuData(imu_data_path)\n",
    "imu_cont.read_imu_csv()\n",
    "imu = imu_cont.acc_read\n",
    "acc, gyro = imu_cont.get_imu_array(['right_wrist','left_wrist','right_elbow', 'left_elbow', 'sternum'])\n",
    "\n",
    "# Creating human model for ground-truth data\n",
    "s = sk_model.create_body_model(os.path.join(subj, action), imu, body_node_list=['ulna_r','ulna_l','humerus_r', 'humerus_l', \"thorax\",\"camera\"])\n",
    "s._nimble.setVelocities(np.zeros((49,1)))\n",
    "s._nimble.setAccelerations(np.zeros((49,1)))\n",
    "start_pos = s._nimble.getPositions()\n",
    "\n",
    "# DH parameters calculation\n",
    "T_list_r, T_list_l = dh_model.compute_list(s)\n",
    "dh_right, offset_right = dh_model.compute_modified_dh(T_list_r, right=True)\n",
    "dh_left, offset_left = dh_model.compute_modified_dh(T_list_l, right=False)\n",
    "\n",
    "# Setting IMU orientation in gt model\n",
    "T = np.array([np.eye(4), np.eye(4), np.eye(4),np.eye(4), np.eye(4), np.eye(4)])\n",
    "T[:,:3,:3] = rotation.batch_quat_to_rotmat(imu_cont.get_world_orient(['right_wrist','left_wrist','right_elbow', 'left_elbow', 'sternum','sternum'])[:,0])\n",
    "sk_model.setImuWorldTransform(s,T)\n",
    "\n",
    "# Creating ArmModel with parameters \n",
    "arm_right = dh_model.ArmModel(dh_right)\n",
    "arm_left = dh_model.ArmModel(dh_left)\n",
    "\n",
    "R_r = dh_model.compute_imu_ori(arm_right,s, T, right= True, initial_guess=np.array([0, -np.pi/2, 0, 0, np.pi/2, 0, -np.pi/2, 0]))\n",
    "R_seg_to_imu_r = [np.eye(3), np.eye(3), R_r[0], np.eye(3), np.eye(3), R_r[1], np.eye(3),R_r[2]] #[R_trunk_IMU, R_upper_IMU, R_fore_IMU]\n",
    "p_seg_to_imu_r = [np.array([0,0,0]), np.array([0,0,0]), np.array([0.1,0.05,-offset_right[0]+0.1]), np.array([0,0,0]), np.array([0,0,0]), np.array([-offset_right[1]*0.5,0,0]), np.array([0,0,0]), np.array([0,0,-offset_right[2]*0.5])]\n",
    "R_seg_to_marker_r = np.eye(3) # Assumpt same orient\n",
    "p_seg_to_marker_r = np.zeros(3)\n",
    "\n",
    "R_l = dh_model.compute_imu_ori(arm_left, s, T, right= False, initial_guess=np.array([np.pi, -np.pi/2, 0, 0, np.pi/2, 0, -np.pi/2, 0]))\n",
    "R_seg_to_imu_l = [np.eye(3), np.eye(3), R_l[0], np.eye(3), np.eye(3), R_l[1], np.eye(3), R_l[2]]\n",
    "p_seg_to_imu_l = [np.array([0,0,0]), np.array([0,0,0]), np.array([0.1,-0.05,-offset_left[0]+0.1]), np.array([0,0,0]), np.array([0,0,0]), np.array([-offset_left[1]*0.5,0,0]), np.array([0,0,0]), np.array([0,0,-offset_left[2]*0.5])] #Riconsidera la prima traslazione sapendo che impatta su dove metti la camera...\n",
    "R_seg_to_marker_l = np.eye(3) \n",
    "p_seg_to_marker_l = np.zeros(3)\n",
    "\n",
    "R_imu_to_cam = R_cam_imu\n",
    "p_imu_to_cam = np.zeros(3)\n",
    "\n",
    "arm_right = dh_model.ArmModel(dh_right, R_seg_to_imu_r, p_seg_to_imu_r,\n",
    "                        R_seg_to_marker_r, p_seg_to_marker_r,\n",
    "                        R_imu_to_cam, p_imu_to_cam)\n",
    "arm_left = dh_model.ArmModel(dh_left, R_seg_to_imu_l, p_seg_to_imu_l,\n",
    "                    R_seg_to_marker_l, p_seg_to_marker_l,\n",
    "                    R_imu_to_cam, p_imu_to_cam)\n",
    "\n",
    "\n",
    "# creation of Q\n",
    "Q_q = np.eye(8)*1e-5\n",
    "Q_qd = np.eye(8)*1e-5\n",
    "Q_qdd = np.eye(8)*1e-5\n",
    "Q_arm = np.block([[Q_q, np.zeros((8,8)), np.zeros((8,8))], [np.zeros((8,8)), Q_qd, np.zeros((8,8))], [np.zeros((8,8)), np.zeros((8,8)), Q_qdd]] )\n",
    "Q_whole = np.block([[Q_arm, np.zeros((24, 24))], [np.zeros((24, 24)),Q_arm]])\n",
    "\n",
    "#Computing initial state throught least square\n",
    "_, q_right = dh_model.compute_world_transf(arm_right, s, right = True, theta_old=np.array([0, -np.pi/2, 0, 0, np.pi/2, 0, -np.pi/2, 0]))\n",
    "_, q_left = dh_model.compute_world_transf(arm_left, s, right = False, theta_old= np.array([np.pi, -np.pi/2, 0, 0, np.pi/2, 0, -np.pi/2, 0]))\n",
    "\n",
    "initial_state = np.zeros(6*8)\n",
    "initial_state[0:8]=q_right\n",
    "initial_state[24:32]=q_left\n",
    "\n",
    "# Kalman filter initialization\n",
    "ekf = kalman.DualArmEKF([arm_right, arm_left],\n",
    "                    Q=Q_whole,\n",
    "                    R_dict={'imu': np.eye(6)*1e-3,\n",
    "                            'marker_pos': np.eye(3)*1e-6,\n",
    "                            'marker_rot': np.eye(3)*1e-3,\n",
    "                            'qr_rot': np.eye(3)*1e-3},\n",
    "                    initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a84184",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_estimation = []\n",
    "\n",
    "for i in range(0, imu['n_frames']):\n",
    "    \n",
    "    # Setting gt position\n",
    "    s._nimble.setPositions(pos_gt[i])\n",
    "    \n",
    "    # Creating IMUs measures tuples list\n",
    "    z_all = [\n",
    "        (0, 2, np.array([gyro[4,i],acc[4,i]*9.80665]).reshape(6)),   # right arm, thorax\n",
    "        (0, 5, np.array([gyro[2,i],acc[2,i]*9.80665]).reshape(6)),   # right arm upper-arm \n",
    "        (0, 7, np.array([gyro[0,i],acc[0,i]*9.80665]).reshape(6)),   # right arm, forearm \n",
    "        (1, 2, np.array([gyro[4,i],acc[4,i]*9.80665]).reshape(6)),   # left_arm, thorax\n",
    "        (1, 5, np.array([gyro[3,i],acc[3,i]*9.80665]).reshape(6)),   # left_arm, upper-arm\n",
    "        (1, 7, np.array([gyro[1,i],acc[1,i]*9.80665]).reshape(6)),   # left_arm, forearm\n",
    "    ]\n",
    "    \n",
    "    # Prediction step of kalman filter\n",
    "    ekf.predict(dt)\n",
    "    \n",
    "    # If is a camera frame, do camera stuff\n",
    "    if i%ratio == 0:\n",
    "        # Get gt camera orientation and position\n",
    "        R_imu_w = rotation.batch_quat_to_rotmat(imu_cont.get_world_orient(['sternum'])[:,i]).reshape(3,3)\n",
    "        R_cam_w = R_imu_w@R_imu_to_cam\n",
    "\n",
    "        camera_pos = sk_model.getImuWorldPosition(s)[5] + R_imu_w@p_imu_to_cam\n",
    "\n",
    "        # Get gt wrists orient\n",
    "        R_l_w = rotation.batch_quat_to_rotmat(imu_cont.get_world_orient(['left_wrist'])[:,i]).reshape(3,3)@R_seg_to_marker_l #(marker -> world) \n",
    "        R_r_w = rotation.batch_quat_to_rotmat(imu_cont.get_world_orient(['right_wrist'])[:,i]).reshape(3,3)@R_seg_to_marker_r\n",
    "\n",
    "        # GT wrists positions and if are visible\n",
    "        pos_target = (s._nimble.getJointWorldPositions(s.joints)).reshape(-1,3)[[1,7],:] - s._nimble.getBodyNode(\"thorax\").getWorldTransform().matrix()[:3,3] #first is left, second is  right\n",
    "        pos_l_w, pos_r_w = input_sim.wrist_camera_simulation(pos_target, camera_pos=camera_pos, R_cam=R_cam_w)\n",
    "        \n",
    "\n",
    "        # World camera orient gt\n",
    "        qr_pos = (camera_pos - s._nimble.getBodyNode(\"thorax\").getWorldTransform().matrix()[:3,3])@R_cam_w\n",
    "        qr_rot = R_cam_w.T\n",
    "\n",
    "        # If specific data available, do the update with that data\n",
    "        if not np.any(np.isnan(pos_r_w)):\n",
    "            try:\n",
    "                ekf.iekf_update_marker(arm_id=0, z_pos=pos_r_w, z_rot=R_r_w)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        if not np.any(np.isnan(pos_l_w)):\n",
    "            try:\n",
    "                ekf.iekf_update_marker(arm_id=1, z_pos=pos_l_w, z_rot=R_l_w)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        try:\n",
    "            ekf.update_qr(arm_id=0, z_rot=qr_rot)\n",
    "        except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        try:\n",
    "            ekf.update_qr(arm_id=1, z_rot=qr_rot)\n",
    "        except Exception as e:\n",
    "                print(e)\n",
    "        \n",
    "    # Updating with IMUs data\n",
    "    try:\n",
    "        ekf.update_imu(z_all, use_joseph=True)\n",
    "    except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "    # Store estimate position\n",
    "    q_est = (ekf.state.reshape(6,8)[[0,3],:])\n",
    "\n",
    "    pos_est_right, _, _ = arm_right.forward_kinematics(q_est[0])\n",
    "    pos_est_left, _, _ = arm_left.forward_kinematics(q_est[1])\n",
    "    pos_est = np.array(pos_est_right + pos_est_left).reshape(-1,3)[[2,5,7,10,13,15],:]\n",
    "\n",
    "    pos_estimation.append(pos_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0666db",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_pose_metrics.save_metrics_comparative(seq_dir=saving_dir, pos_estimation = pos_estimation, marker = target, offset=offset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
